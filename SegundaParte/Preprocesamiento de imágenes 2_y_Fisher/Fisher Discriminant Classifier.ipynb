{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.udem.edu.co/\"><img src=\"Escudo.png\"></a>\n",
    "<h1>Reconocimiento de Patrones I y II</h1>\n",
    "<h2>Clasificador discriminante de Fisher</h2>\n",
    "<h3>2018-2</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo clasificador discriminante de Fisher es un modelo lineal que permite resolver problemas de clasificación (reconocimiento de patrones) a partir de la búsqueda de una frontera de decisión (hiperplano) que separa las clases del problema (Así como regresión logística, feed-forward neural networks, support vector machines).\n",
    "\n",
    "<img src=\"class_problem.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El clasificador discriminante de Fisher, usa información de variables estadísticas (vectores de media y matrices de varianza y covarianza) para poder trazar el modelo que nos servirá para discriminar nuestras clases. Su regla (condición de decisión) de clasificación es la siguiente:\n",
    "\n",
    "$W'X < W'*(\\frac{\\mu_1+\\mu_2}{2})$\n",
    "\n",
    "Donde:\n",
    "\n",
    "$W = Sw^{-1}*(\\mu_1-\\mu_2)$\n",
    "\n",
    "$W’ = $ transpuesta de $W$\n",
    "\n",
    "$Sw = ((n1 -1) / n1 + n2 -2)*S1 +  ((n2 -1) / n1 + n2 -2  )*S2$\n",
    "\n",
    "$S1 , S2 = $ Matriz de covarianzas para la clase 1 y la clase 2\n",
    " \n",
    "$n1, n2 =$ cantidad de elementos de la clase 1 y cantidad de elementos de la clase 2\n",
    "\n",
    "$\\mu_1, \\mu_2$ = vectores de medias para las clases 1 y 2 respectivamente.\n",
    "\n",
    "Nota: a $Sw$ se le conoce como matriz de intra-grupos combinada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos y Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponga que tiene una base de datos como la que se muestra en la siguiente figura:\n",
    "\n",
    "<img src=\"Data.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.846887  , -1.7495969 ],\n",
       "       [ 0.99073559,  1.98760889]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "U0X1 = [2.5, 3, 1, 4, 2]\n",
    "U1X1 = [10.5, 7, 4.5, 6.5, 7.5]\n",
    "\n",
    "U0X2 = [12.5, 8.5, 5.4, 15, 8.5]\n",
    "U1X2 = [2.5, 2, 0.5, 1, 2.5]\n",
    "\n",
    "\n",
    "U1X1_media = np.mean(U1X1)\n",
    "U1X2_media = np.mean(U1X2)\n",
    "\n",
    "valx1 = 0\n",
    "for num in U1X1:\n",
    "    valx1 += (num - U1X1_media)**2\n",
    "\n",
    "valx2 = 0\n",
    "for num in U1X2:\n",
    "    valx2 += (num - U1X2_media)**2\n",
    "    \n",
    "a = 0\n",
    "for x1, x2 in zip(U1X1, U1X2):\n",
    "    a += (x1 - U1X1_media)*(x2 - U1X2_media)\n",
    "\n",
    "\n",
    "s1 = np.array([[1/5 * valx1 , 1/5 * a], [1/5 * a, 1/5 * valx2]])\n",
    "s2 = np.array([[1, 2.88], [2.88, 11.38]])\n",
    "sw = s1*0.5 + 0.5*s2\n",
    "\n",
    "sw_inversa = np.linalg.inv(sw)\n",
    "\n",
    "u = np.array([-4.7, 8.3]).reshape(2,1)\n",
    "a = sw_inversa * u\n",
    "\n",
    "a.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.382"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1/5)*(2.25+6.25+2.25+21.16+25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo en Python\n",
    "\n",
    "Trabajaremos con la base de datos IRIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "db = datasets.load_iris()\n",
    "X = db.data\n",
    "Y = db.target\n",
    "#print(db.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialmente con un problema biclase\n",
    "\n",
    "Tomaremos las clases setosa y versicolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[0:100,:]\n",
    "Y = Y[0:100]\n",
    "#print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos las muestras de ambas clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestras de entrenamientos\n",
    "\n",
    "Xsetosa = X[0:40,:]\n",
    "Ysetosa = Y[0:40]\n",
    "\n",
    "Xversicolor = X[50:90,:]\n",
    "Yversicolor = Y[50:90]\n",
    "\n",
    "# Muestras para validación\n",
    "\n",
    "Xsetosa_test = X[40:50,:]\n",
    "Ysetosa_test = Y[40:50]\n",
    "\n",
    "Xversicolor_test = X[90:100,:]\n",
    "Yversicolor_test = Y[90:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos los elementos que se requieren para aplicar el método clasificador discriminante de Fisher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector de medias setosa =  [5.0375 3.44   1.4625 0.2325]\n",
      "Vector de medias versicolor =  [6.01   2.78   4.3175 1.35  ]\n"
     ]
    }
   ],
   "source": [
    "#vectores de medias de ambas clases\n",
    "\n",
    "mu1 = np.mean(Xsetosa, axis=0)\n",
    "mu2 = np.mean(Xversicolor, axis=0)\n",
    "print('Vector de medias setosa = ', mu1)\n",
    "print('Vector de medias versicolor = ', mu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1 (setosa) = \n",
      " [[0.13112179 0.09897436 0.01298077 0.01362179]\n",
      " [0.09897436 0.13271795 0.00205128 0.0145641 ]\n",
      " [0.01298077 0.00205128 0.02958333 0.00458333]\n",
      " [0.01362179 0.0145641  0.00458333 0.00994231]]\n",
      "S2 (versicolor) = \n",
      " [[0.27374359 0.08661538 0.17212821 0.05230769]\n",
      " [0.08661538 0.11087179 0.08087179 0.04538462]\n",
      " [0.17212821 0.08087179 0.20353205 0.07371795]\n",
      " [0.05230769 0.04538462 0.07371795 0.04307692]]\n"
     ]
    }
   ],
   "source": [
    "#Matrices de covarianzas S1 y S2\n",
    "\n",
    "S1 = np.cov(Xsetosa, rowvar=False)\n",
    "S2 = np.cov(Xversicolor, rowvar=False)\n",
    "\n",
    "print('S1 (setosa) = \\n', S1)\n",
    "print('S2 (versicolor) = \\n', S2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se computa $Sw$:\n",
    "\n",
    "$Sw = ((n1 -1) / n1 + n2 -2) S1 +  ((n2 -1) / n1 + n2 -2  ) S2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sw = \n",
      " [[0.24962986 0.10772856 0.12223176 0.04198331]\n",
      " [0.10772856 0.1409107  0.05540495 0.03779929]\n",
      " [0.12223176 0.05540495 0.15164943 0.05186063]\n",
      " [0.04198331 0.03779929 0.05186063 0.03393667]]\n"
     ]
    }
   ],
   "source": [
    "n1 = np.size(Xsetosa,0)\n",
    "n2 = np.size(Xversicolor,0)\n",
    "\n",
    "\n",
    "Sw = (((n1-1)/(n1+n2-2))*S1) + (((n2-1)/(n1+n2-22))*S2)\n",
    "print('Sw = \\n', Sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora computamos W\n",
    "\n",
    "$W= Sw^{-1}  (VectorMediasClase1  -  VectorMediasClase2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = \n",
      " [[  1.27310256]\n",
      " [ 18.10241936]\n",
      " [-16.27838645]\n",
      " [-29.79079159]]\n"
     ]
    }
   ],
   "source": [
    "Swinv = np.linalg.inv(Sw)\n",
    "#print(Swinv.shape)\n",
    "#print(mu1.shape)\n",
    "#print(mu2.shape)\n",
    "mu1 = mu1.reshape(4,1)\n",
    "mu2 = mu2.reshape(4,1)\n",
    "W = np.dot(Swinv,(mu1-mu2))\n",
    "W = W.reshape(4,1)\n",
    "print('W = \\n', W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora computamos la salida del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.28567624]]\n",
      "Salida del modelo = \n",
      " -7.285676242345488\n"
     ]
    }
   ],
   "source": [
    "#print(W.T.shape)\n",
    "#print(((mu1+mu2)/2).shape)\n",
    "Modelo = np.dot(W.T,((mu1+mu2)/2))\n",
    "print(Modelo)\n",
    "print('Salida del modelo = \\n', Modelo[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para saber cómo determinar si una nueva muestra es clase 0 (setosa) o clase 1 (versicolor), se prueba una muestra de training en el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43.47796744]\n"
     ]
    }
   ],
   "source": [
    "#Probemos con una muestra de la clase setosa a ver que nos entrega.\n",
    "\n",
    "prueba_setosa = np.dot(W.T, Xsetosa[10,:])\n",
    "print(prueba_setosa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-44.19479267]\n"
     ]
    }
   ],
   "source": [
    "#Probemos con una muestra de la clase versicolor a ver que nos entrega.\n",
    "\n",
    "prueba_versicolor = np.dot(W.T, Xversicolor[10,:])\n",
    "print(prueba_versicolor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya sabemos entonces que si a la salida obtenemos un valor mayor que -7.2856, entonces la muestra estará por encima de la frontera y será de la clase setosa, en caso contrario estará por debajo de la frontera y será de la clase versicolor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probando el clasificador con las muestras de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados:\n",
      "\n",
      "Eficiencia =  1.0 \n",
      "Sensibilidad =  1.0 \n",
      "Especificidad =  1.0\n"
     ]
    }
   ],
   "source": [
    "TP,FP,TN,FN = 0,0,0,0\n",
    "Sensibilidad = 0\n",
    "Especificidad = 0\n",
    "Eficiencia = 1\n",
    "\n",
    "\n",
    "for i in Xsetosa_test:\n",
    "    salida = np.dot(W.T,i)\n",
    "    if salida > -7.2856:\n",
    "        TN += 1\n",
    "    else:\n",
    "        FP += 1\n",
    "        \n",
    "for j in Xversicolor_test:\n",
    "    salida = np.dot(W.T,j)\n",
    "    if salida <= -7.2856:\n",
    "        TP += 1\n",
    "    else:\n",
    "        FN += 1\n",
    "        \n",
    "Sensibilidad = TP/(TP+FN)\n",
    "Especificidad = TN/(TN+FP)\n",
    "Eficiencia = (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "print('Resultados:\\n\\nEficiencia = ', Eficiencia, '\\nSensibilidad = ', Sensibilidad, '\\nEspecificidad = ', Especificidad)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué pasa si tengo un problema multiclase?\n",
    "\n",
    "Existen diferentes estrategias para abordar este problema, con el fin de resolver problemas multiclase con modelos que inicialmente han sido diseñados para resolver problemas biclase. En el curso abordaremos dos estrategias:\n",
    "\n",
    "1. One vs. One\n",
    "2. One vs. All\n",
    "\n",
    "Material desarrollado en clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "Resolver el problema de clasificación de la base de datos IRIS con el modelo clasificador discrimiante de Fisher, aplicando la estrategia One vs. One."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
