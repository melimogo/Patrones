{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.udem.edu.co/\"><img src=\"Escudo.png\"></a>\n",
    "<h1>Reconocimiento de Patrones I y II</h1>\n",
    "<h2>Operaciones de transformación de imágenes</h2>\n",
    "<h3>2018-2</h3>\n",
    "<h4>Integrantes</h4>\n",
    "<h5>Nombre: Ana Maria Sosa - Identificación: 1017235052</h5>\n",
    "<h5>Nombre: Miguel Ángel Mejia - Identificación: 1036646927</h5>\n",
    "<h5>Nombre: Melisa Morales Gómez - Identificación: 1035875351</h5> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melim\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import exposure\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, square\n",
    "from skimage.segmentation import clear_border\n",
    "from sklearn import cross_validation\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se declara la lista para las imágenes y las etiquetas posibles\n",
    "moras = []\n",
    "clases = [\"malas\", \"regulares\", \"buenas\"]\n",
    "\n",
    "#Se declaran las variables para encontrar el umbral y binarizar\n",
    "image = data.camera()\n",
    "thresh = threshold_otsu(image)\n",
    "binary = image > thresh\n",
    "\n",
    "#Se recorren las carpetas leyendo los archivos, preprocesandolos y llevandolos a una lista\n",
    "for i in clases:\n",
    "    for j in range(1,81):\n",
    "        # Se importa la imagen\n",
    "        imagen = \"Moras \" + i + \"/ImagenMora\" + str(j) +\".jpg\"\n",
    "        img_mora = Image.open(imagen)\n",
    "        # Convertir a escala de grises\n",
    "        img_mora = img_mora.convert('L')       \n",
    "        # Convertir a float32\n",
    "        img_mora = np.asarray(img_mora,dtype=np.float32)\n",
    "        # Se reescala la intensidad de las imágenes\n",
    "        p2, p98 = np.percentile(img_mora, (1, 98))\n",
    "        img_mora = exposure.rescale_intensity(img_mora, in_range=(p2, p98))        \n",
    "        # Se encuentra el umbral\n",
    "        thresh1 = threshold_otsu(img_mora)\n",
    "        # Se binariza\n",
    "        binary1 = img_mora < thresh1\n",
    "        # Se guarda la imagen binarizada\n",
    "        moras.append((binary1, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # Datos\n",
    "y = [] # Etiquetas\n",
    "\n",
    "# Se caracterizan las imágenes usando regionprops\n",
    "for i in range (240):    \n",
    "    label_img = label(moras[i][0])\n",
    "    regions = regionprops(label_img)\n",
    "    \n",
    "    #Se encuentra la región con el área más grande y esa corresponde a la región a la que se le extraen las carácteristicas\n",
    "    if i >= 160: #Moras buenas\n",
    "        characteristics = [] \n",
    "        area = 0\n",
    "        regionNumber = 0\n",
    "        cont = 0\n",
    "        for j in regions:\n",
    "            if j.area > area:\n",
    "                area = j.area                \n",
    "                regionNumber = cont  \n",
    "                cont += 1\n",
    "        # Se llevan las carácteristicas a una lista\n",
    "        characteristics.append(area)      \n",
    "        characteristics.append(regions[regionNumber].bbox_area)       \n",
    "        characteristics.append(regions[regionNumber].convex_area)      \n",
    "        characteristics.append(regions[regionNumber].eccentricity)        \n",
    "        characteristics.append(regions[regionNumber].equivalent_diameter)     \n",
    "        characteristics.append(regions[regionNumber].euler_number)\n",
    "        characteristics.append(regions[regionNumber].extent)\n",
    "        characteristics.append(regions[regionNumber].filled_area)   \n",
    "        characteristics.append(regions[regionNumber].orientation)  \n",
    "        characteristics.append(regions[regionNumber].perimeter)  \n",
    "        characteristics.append(regions[regionNumber].solidity)        \n",
    "        X.append(characteristics)        \n",
    "        y.append(2)    \n",
    "    elif i >= 80: #Moras regulares\n",
    "        characteristics = [] \n",
    "        area = 0\n",
    "        regionNumber = 0\n",
    "        cont = 0\n",
    "        for j in regions:\n",
    "            if j.area > area:\n",
    "                area = j.area                \n",
    "                regionNumber = cont  \n",
    "                cont += 1\n",
    "        characteristics.append(area)      \n",
    "        characteristics.append(regions[regionNumber].bbox_area)       \n",
    "        characteristics.append(regions[regionNumber].convex_area)      \n",
    "        characteristics.append(regions[regionNumber].eccentricity)        \n",
    "        characteristics.append(regions[regionNumber].equivalent_diameter)     \n",
    "        characteristics.append(regions[regionNumber].euler_number)\n",
    "        characteristics.append(regions[regionNumber].extent)\n",
    "        characteristics.append(regions[regionNumber].filled_area)   \n",
    "        characteristics.append(regions[regionNumber].orientation)  \n",
    "        characteristics.append(regions[regionNumber].perimeter)  \n",
    "        characteristics.append(regions[regionNumber].solidity)        \n",
    "        X.append(characteristics)    \n",
    "        y.append(1)\n",
    "    else: #Moras malas\n",
    "        characteristics = [] \n",
    "        area = 0\n",
    "        regionNumber = 0\n",
    "        cont = 0\n",
    "        for j in regions:\n",
    "            if j.area > area:\n",
    "                area = j.area                \n",
    "                regionNumber = cont  \n",
    "                cont += 1\n",
    "        characteristics.append(area)      \n",
    "        characteristics.append(regions[regionNumber].bbox_area)       \n",
    "        characteristics.append(regions[regionNumber].convex_area)      \n",
    "        characteristics.append(regions[regionNumber].eccentricity)        \n",
    "        characteristics.append(regions[regionNumber].equivalent_diameter)     \n",
    "        characteristics.append(regions[regionNumber].euler_number)\n",
    "        characteristics.append(regions[regionNumber].extent)\n",
    "        characteristics.append(regions[regionNumber].filled_area)   \n",
    "        characteristics.append(regions[regionNumber].orientation)  \n",
    "        characteristics.append(regions[regionNumber].perimeter)  \n",
    "        characteristics.append(regions[regionNumber].solidity)        \n",
    "        X.append(characteristics)    \n",
    "        y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import cross_validation \n",
    "\n",
    "def SupportVectorMachine(datos,C_,gamma_):\n",
    "    kf = cross_validation.KFold(240,n_folds=10)\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(datos, y, test_size=0.3)\n",
    "    clf = svm.SVC(C=C_,kernel='rbf', gamma=gamma_,decision_function_shape='ovo')\n",
    "    clf.fit(X_train, y_train) \n",
    "    Yest = clf.predict(X_test)\n",
    "    resultados = cross_validation.cross_val_score(clf, X_test, y_test, cv=10)\n",
    "    eficiencia = str(resultados.mean() + \" +/- \" + (resultados.std() * 2))\n",
    "    error = str((1 - resultados.mean()) +  \"+/- \" + (resultados.std() * 2))\n",
    "    return eficiencia,error\n",
    "\n",
    "def tablaSupportVectorMachine(datos):\n",
    "    eficiencias = []\n",
    "    errores = []\n",
    "    C=[1,10,100]\n",
    "    gamma=[0.0001,0.001, 0.01, 0.1]\n",
    "    for i in C:\n",
    "        for j in gamma:\n",
    "            eficiencia,error = SupportVectorMachine(datos,i,j)\n",
    "            eficiencias.append(eficiencia)\n",
    "            errores.append(error)\n",
    "    medidasDict = {\n",
    "        'Valor de C': C, \n",
    "        'Valor de Gamma': gamma, \n",
    "        'Eficiencia': eficiencia,\n",
    "        'Error': error\n",
    "        }\n",
    "    tabla = pd.DataFrame(data=medidasDict)\n",
    "    \n",
    "    print(tabla)\n",
    "\n",
    "print('\\n','╒═══════════════════ Support Vector Machine ════════════════════════════════════╕','\\n')\n",
    "print('Support vector Machine',' \\n')\n",
    "tablaSupportVectorMachine(X)\n",
    "print('╘═══════════════════════════════════════════════════════════════════════════════════╛', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "\n",
    "def RandomForest(bd,arbol):\n",
    "    kf = cross_validation.KFold(240,n_folds=10)\n",
    "    clf = RF(n_estimators=arbol)\n",
    "    for k, (train,test) in enumerate(kf):\n",
    "        Xtrain,Xtest,Ytrain,Ytest = cross_validation.train_test_split(bd,y,test_size=0.3)  \n",
    "        clf.fit(Xtrain,Ytrain)\n",
    "    resultados = cross_validation.cross_val_score(clf, Xtest, Ytest, cv=10)\n",
    "    eficiencia = str(resultados.mean() + \" +/- \" + (resultados.std() * 2))\n",
    "    error = str((1 - resultados.mean()) +  \"+/- \" + (resultados.std() * 2))\n",
    "    return eficiencia,error\n",
    "\n",
    "def tablaRandomForest(datos):\n",
    "    numeroArboles = [10,20,30,40,100]\n",
    "    errores, sensibilidades, especificidades = [],[],[]\n",
    "    for i in numeroVecinos:\n",
    "        eficiencia,error = KNearestNeighbors(datos,i)\n",
    "        eficiencias.append(eficiencia)\n",
    "        errores.append(error)\n",
    "\n",
    "    medidasDict = {\n",
    "        '# Arboles': numeroArboles, \n",
    "        'Eficiencia': eficiencias, \n",
    "        'Error': errores\n",
    "        }\n",
    "    tabla = pd.DataFrame(data=medidasDict)\n",
    "    \n",
    "\n",
    "print('\\n','╒═══════════════════ Random forest ════════════════════════════════════╕','\\n')\n",
    "print('Random forest',' \\n')\n",
    "tablaRandomForest(X)\n",
    "print('╘═══════════════════════════════════════════════════════════════════════════════════╛', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def DecisionTree(bd):\n",
    "    for k, (train, test) in enumerate(kf):\n",
    "        X_train, X_test, y_train, y_test = cross_validation.train_test_split(bd, y, test_size=0.3)\n",
    "        clf = DecisionTreeClassifier(criterion='gini', random_state=0)\n",
    "        clf.fit(X_train,y_train)\n",
    "        Yest = clf.predict(X_test)\n",
    "    resultados = cross_validation.cross_val_score(clf, X_test, y_test, cv=10)\n",
    "    eficiencia = str(resultados.mean() + \" +/- \" + (resultados.std() * 2))\n",
    "    error = str((1 - resultados.mean()) +  \"+/- \" + (resultados.std() * 2))\n",
    "    return eficiencia,error\n",
    "\n",
    "def tablaDecisionTree(datos):\n",
    "    eficiencia, error  = DecisionTree(datos)\n",
    "\n",
    "    medidasDict = {\n",
    "        'Eficiencia': eficiencia, \n",
    "        'Error': error\n",
    "        }\n",
    "    tabla = pd.DataFrame(data=medidasDict)\n",
    "    \n",
    "    print(tabla)\n",
    "    \n",
    "print('\\n','╒═══════════════════ Arboles de decisión ══════════════════════════════════════╕','\\n')\n",
    "print('Arboles de decisión',' \\n')\n",
    "tablaDecisionTree(X)\n",
    "print('╘═══════════════════════════════════════════════════════════════════════════════════╛', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
