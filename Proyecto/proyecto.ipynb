{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Estudiantes\n",
    "\n",
    "Nombre: Ana Maria Sosa\n",
    "\n",
    "Identificación: 1017235052\n",
    "    \n",
    "Nombre: Miguel Ángel Mejia\n",
    "    \n",
    "Identificación: 1036646927\n",
    "\n",
    "Nombre: Melisa Morales Gómez\n",
    "    \n",
    "Identificación: 1035875351"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Organizar la base de datos.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Documentos  Clase\n",
      "0   Excelente. Recomendable. Habitaciones cómodas ...      1\n",
      "1   Las habitaciones muy amplias así como la cama....      1\n",
      "2   La piscina y el bungalow son muy espaciosos y ...      1\n",
      "3   El desayuno bufett bastante bueno, cuenta con ...      1\n",
      "4   La ubicación del hotel es perfecta para descan...      1\n",
      "5   Muy bien el transporte de y hacia el aeropuert...      1\n",
      "6   Las instalaciones en general estupendas, nuest...      1\n",
      "7   La piscina fantástica. Perfecto para un respir...      1\n",
      "8   La piscina principalmente. Tienes servicio de ...      1\n",
      "9   El sitio es excelente y la atencion un lujo.. ...      1\n",
      "10  La habitación era un maravilla, amplia y confo...      1\n",
      "11  Muy lindo, ubicado en zona residencial muy linda.      1\n",
      "12  La habitación muy limpia, excelente el conduct...      1\n",
      "13  Buen trato y la tranquilidad. A parte de estar...      1\n",
      "14  Todo el hotel está muy bueno  sin problemas es...      1\n",
      "15  Un hotel perfecto para esperar tu vuelo, pisci...      1\n",
      "16  El entorno super agradable y tranquilo, no par...      1\n",
      "17  El ambiente es maravillosamente tranquilo, la ...      1\n",
      "18  Todo, muy cómodo, tranquilo, limpio, buena com...      1\n",
      "19  EL hotel de lujo en general, el personal muy a...      1\n",
      "20  El servicio de transporte gratuito al aeropuer...      1\n",
      "21  La ubicación. El departamento amplio bien vent...      1\n",
      "22  Es muy cálido, muy buena atención, muy cómodo ...      1\n",
      "23  Excelente ubicación. Cercano al aeropuerto y s...      1\n",
      "24  Todo completo, nevera, baño con todos accesori...      1\n",
      "25  El hotel está perfectamente equipado, las habi...      1\n",
      "26  No desayuné, ni necesité el aire acondicionado...      1\n",
      "27  Muy buena atención y trato por parte del perso...      1\n",
      "28  Cama muy cómoda, piscina y distribución de las...      1\n",
      "29  El personal muy amable,cama amplia y todo muy ...      1\n",
      "..                                                ...    ...\n",
      "70  La moqueta estaba sucia y hundida, el ruido de...      0\n",
      "71  Falta de limpieza en las habitaciones (había h...      0\n",
      "72  estaba muy sucio y descuidado , pelos en el ba...      0\n",
      "73  la limpieza brillaba por su ausencia hotel car...      0\n",
      "74  Nada. Personal impresentable, mal educado.Desc...      0\n",
      "75  Las instalaciones del supuesto hotel 4 estrell...      0\n",
      "76  Instalaciones obsoletas, equipamiento obsoleto...      0\n",
      "77  La habitación estaba fatal,toalla manchada y s...      0\n",
      "78  Un hotel de 4 estrella no puede tener habitaci...      0\n",
      "79  Parking peligroso, incómodo, cutre Habitación ...      0\n",
      "80  El desayuno pobre y de mala calidad. El servic...      0\n",
      "81  Que las fotos son engañosas. Y una una vergüen...      0\n",
      "82  Es increible que un hotel como ese tenga 4 est...      0\n",
      "83  Ubicación muy mal , servicio mal, para subir a...      0\n",
      "84  Es un hotel de 4* y nos metieron en un bungalo...      0\n",
      "85            Todo en general bastante cutre y sucio.      0\n",
      "86  Las camas incomodas y rotas, los baños viejos,...      0\n",
      "87  La ventana de la habitacion estaba rota (no ce...      0\n",
      "88  Un hotel muy viejo falta de higiene precios de...      0\n",
      "89  Este hotel es fatal.  Me quedo esperando en el...      0\n",
      "90  Instalaciones obsoletas, equipamiento obsoleto...      0\n",
      "91  No, me gusto nada, la habitación era un bungal...      0\n",
      "92  El suelo de la habitación con moqueta muy suci...      0\n",
      "93  En las fotos parecía un magnífico hotel, con p...      0\n",
      "94  Parquing incómodo y caro, horario de la piscin...      0\n",
      "95  Las habitaciones están descuidadas, el persona...      0\n",
      "96  Servicio, los precios, la habitación no podía ...      0\n",
      "97  Es muy viejo, està un poco sucio. No hay posib...      0\n",
      "98  La habitación vieja, el aire acondicionado vie...      0\n",
      "99  Estaba muy sucio. Creo que debería recibir una...      0\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Fuente base de datos, Hotel Osuna Feria Madrid\n",
    "# https://goo.gl/mJfYqP\n",
    "db = pd.read_csv(\"BD.txt\", delimiter=\"\\t\")\n",
    "print(db)\n",
    "y = np.zeros(100)\n",
    "#Archivo solo con los documentos\n",
    "f = open ('Docs.txt','w')\n",
    "for i in range(len(db)):\n",
    "    y[i] = db['Clase'][i]\n",
    "    f.write(db['Documentos'][i] + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar la base de datos de MLSenticon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import requests\n",
    "\n",
    "sentimientos = open('MLSenticon.txt', 'r')\n",
    "\n",
    "MLSenticonDic = { }\n",
    "for word in sentimientos:\n",
    "    palabra = word.split('\\t')[0]\n",
    "    valor = float(word.split('\\t')[1][:-1])\n",
    "    MLSenticonDic[palabra] = valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caracterización para Positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcularPolaridad(sentence):\n",
    "    for word in sentence:\n",
    "        palabra =  str(word['token'])\n",
    "        if palabra.lower() == 'no' or palabra.lower() == 'pero':\n",
    "            return -1 #Cambia la polaridad\n",
    "    return 1 #No cambia la polaridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizado...\n"
     ]
    }
   ],
   "source": [
    "CaracteristicasPos = []\n",
    "for i in range(50):\n",
    "    vectorCaracteristicasPos = [0,0]\n",
    "    \n",
    "    f = open ('Coment.txt','w')\n",
    "    f.write(db['Documentos'][i] + '\\n')\n",
    "    f.close()\n",
    "    #print(db['Documentos'][i])\n",
    "    \n",
    "    #Archivo a ser enviado\n",
    "    files = {'file': open('Coment.txt', 'r')}\n",
    "    \n",
    "    #Parámetros\n",
    "    params = {'outf': 'tagged', 'format': 'json'}\n",
    "\n",
    "    #Enviar petición\n",
    "    url = \"http://www.corpus.unam.mx/servicio-freeling/analyze.php\"\n",
    "    r = requests.post(url, files=files, params=params)\n",
    "    #print (r)\n",
    "\n",
    "    #Convertir de formato json\n",
    "    obj = r.json()\n",
    "\n",
    "    #pint(len(obj))    #obj es una lista de listas. Tiene tantos elementos (listas) como frases tenga el file\n",
    "    \n",
    "    #Ejemplo, obtener todos los lemas\n",
    "    for sentence in obj:\n",
    "        #print (sentence)    #sentence es una lista de diccionarios. Tiente tantos elementos (diccionarios)\n",
    "                             #como palabras tiene la frase\n",
    "        polaridad = CalcularPolaridad(sentence)\n",
    "        for word in sentence:\n",
    "            #word es un diccionario con 4 claves: token, lemma, tag y prob(probabilidad de que el tag haya sido bien asignado)\n",
    "            #A través de esas cuatro claves se podrá acceder a la información que requerimos para\n",
    "            #Comenzar a construir el vector de características de un texto\n",
    "            #print(word)\n",
    "            if (word['tag'][0] == 'A'):\n",
    "                    lema = word['lemma']\n",
    "                    #print(lema)\n",
    "                    \n",
    "                    try: \n",
    "                        valor = MLSenticonDic[lema]\n",
    "                    except:\n",
    "                        valor = 0\n",
    "\n",
    "                    if polaridad == 1:\n",
    "                        if (valor > 0):\n",
    "                            vectorCaracteristicasPos[0] += valor\n",
    "                        else:\n",
    "                            vectorCaracteristicasPos[1] += valor\n",
    "                    else:\n",
    "                        if (valor > 0):\n",
    "                            vectorCaracteristicasPos[1] += (valor * polaridad)\n",
    "                        else:\n",
    "                            vectorCaracteristicasPos[0] += (valor * polaridad)\n",
    "\n",
    "        #print(vectorCaracteristicasPos)\n",
    "    CaracteristicasPos.append(vectorCaracteristicasPos)\n",
    "#print(CaracteristicasPos)\n",
    "print(\"Finalizado...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caracterización para negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizado\n"
     ]
    }
   ],
   "source": [
    "CaracteristicasNeg = []\n",
    "for i in range(50,100):\n",
    "    vectorCaracteristicasNeg = [0,0]\n",
    "    \n",
    "    f = open ('Coment.txt','w')\n",
    "    f.write(db['Documentos'][i] + '\\n')\n",
    "    f.close()\n",
    "    #print(db['Documentos'][i])\n",
    "    \n",
    "    #Archivo a ser enviado\n",
    "    files = {'file': open('Coment.txt', 'r')}\n",
    "    \n",
    "    #Parámetros\n",
    "    params = {'outf': 'tagged', 'format': 'json'}\n",
    "\n",
    "    #Enviar petición\n",
    "    url = \"http://www.corpus.unam.mx/servicio-freeling/analyze.php\"\n",
    "    r = requests.post(url, files=files, params=params)\n",
    "    #print (r)\n",
    "\n",
    "    #Convertir de formato json\n",
    "    obj = r.json()\n",
    "\n",
    "    #pint(len(obj))    #obj es una lista de listas. Tiene tantos elementos (listas) como frases tenga el file\n",
    "    \n",
    "    #Ejemplo, obtener todos los lemas\n",
    "    for sentence in obj:\n",
    "        #print (sentence)    #sentence es una lista de diccionarios. Tiente tantos elementos (diccionarios)\n",
    "                             #como palabras tiene la frase\n",
    "        polaridad = CalcularPolaridad(sentence)\n",
    "        for word in sentence:\n",
    "            #word es un diccionario con 4 claves: token, lemma, tag y prob(probabilidad de que el tag haya sido bien asignado)\n",
    "            #A través de esas cuatro claves se podrá acceder a la información que requerimos para\n",
    "            #Comenzar a construir el vector de características de un texto\n",
    "            #print(word)\n",
    "            if (word['tag'][0] == 'A'):\n",
    "                    lema = word['lemma']\n",
    "                    #print(lema)\n",
    "\n",
    "                    try: \n",
    "                        valor = MLSenticonDic[lema]\n",
    "                    except:\n",
    "                        valor = 0\n",
    "                        \n",
    "                    if polaridad == 1:\n",
    "                        if (valor > 0):\n",
    "                            vectorCaracteristicasNeg[0] += valor\n",
    "                        else:\n",
    "                            vectorCaracteristicasNeg[1] += valor\n",
    "                    else:\n",
    "                        if (valor > 0):\n",
    "                            vectorCaracteristicasNeg[1] += (valor * polaridad)\n",
    "                        else:\n",
    "                            vectorCaracteristicasNeg[0] += (valor * polaridad)\n",
    "                    \n",
    "\n",
    "        #print(vectorCaracteristicasNeg)\n",
    "    CaracteristicasNeg.append(vectorCaracteristicasNeg)\n",
    "#print(CaracteristicasNeg)\n",
    "print(\"Finalizado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector completo de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Caracteristicas = CaracteristicasPos + CaracteristicasNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "\n",
    "def error_measures(Yestimado, Yteorico):\n",
    "    \n",
    "    CM = confusion_matrix(Yteorico, Yestimado)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    \n",
    "    sens = TP/(TP+FN)\n",
    "    esp = TN/(TN+FP)\n",
    "    \n",
    "    return sens, esp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de funciones de clasificación "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logistica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.17566666666666664\n",
      "Sensitivity:  0.8361293592794636\n",
      "Especificity:  0.8157187485287329\n"
     ]
    }
   ],
   "source": [
    "def RegresionLogistica(db):\n",
    "    lr=LogisticRegression()\n",
    "    acc = []\n",
    "    sens = []\n",
    "    esp = []\n",
    "\n",
    "    for i in range(100):\n",
    "\n",
    "        Xtrain,Xtest,Ytrain,Ytest = train_test_split(db,y,test_size=0.3)   #Preguntar bootstraping\n",
    "\n",
    "\n",
    "        lr.fit(Xtrain,Ytrain)\n",
    "        Yest = lr.predict(Xtest)\n",
    "        s, e = error_measures(Yest,Ytest)\n",
    "        sens.append(s); esp.append(e)\n",
    "        acc.append(lr.score(Xtest,Ytest))\n",
    "\n",
    "    #print(\"Muestras training: \", round((np.size(Xtrain,0)*100)/100), \"%\")\n",
    "    #print(\"Muestras testing: \", round((np.size(Xtest,0)*100)/100), \"%\")\n",
    "\n",
    "    #print(\"\\nResultados con Regresión logística (Lineal)\\n\")\n",
    "    #print(\"Accuracy: \", np.mean(acc), \"+/-\", np.std(acc))\n",
    "    #print(\"Sensitivity: \", np.mean(sens), \"+/-\", np.std(sens))\n",
    "    #print(\"Especificity: \", np.mean(esp), \"+/-\", np.std(esp))\n",
    "    return 1-np.mean(acc),np.mean(sens),np.mean(esp)\n",
    "    \n",
    "a,b,c = RegresionLogistica(Caracteristicas)\n",
    "print(\"Accuracy: \", a)\n",
    "print(\"Sensitivity: \", b)\n",
    "print(\"Especificity: \", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.15300000000000002\n",
      "Sensitivity:  0.8674022595481574\n",
      "Especificity:  0.8313724040837045\n"
     ]
    }
   ],
   "source": [
    "def KNearestNeighbors(bd,vecinos):\n",
    "    acc = []\n",
    "    sens = []\n",
    "    esp = []\n",
    "\n",
    "    #Complete el código para KNN\n",
    "    neigh = KNN(n_neighbors=vecinos)\n",
    "\n",
    "    for i in range(100):\n",
    "\n",
    "        Xtrain,Xtest,Ytrain,Ytest = train_test_split(bd,y,test_size=0.3)   \n",
    "\n",
    "        neigh.fit(Xtrain,Ytrain)\n",
    "        Yest = neigh.predict(Xtest)\n",
    "        s, e = error_measures(Yest,Ytest)\n",
    "        sens.append(s); esp.append(e)\n",
    "        acc.append(neigh.score(Xtest,Ytest))\n",
    "\n",
    "\n",
    "    #print(\"\\nResultados con K vecinos más cercanos\\n\")\n",
    "    #print(\"Accuracy: \", np.mean(acc), \"+/-\", np.std(acc))\n",
    "    #print(\"Sensitivity: \", np.mean(sens), \"+/-\", np.std(sens))\n",
    "    #print(\"Especificity: \", np.mean(esp), \"+/-\", np.std(esp))\n",
    "    return 1-np.mean(acc),np.mean(sens),np.mean(esp)\n",
    "\n",
    "\n",
    "a,b,c = KNearestNeighbors(Caracteristicas,15)\n",
    "print(\"Accuracy: \", a)\n",
    "print(\"Sensitivity: \", b)\n",
    "print(\"Especificity: \", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.15699999999999992\n",
      "Sensitivity:  0.7911997805256319\n",
      "Especificity:  0.8958375421877746\n"
     ]
    }
   ],
   "source": [
    "def RandomForest(bd,arboles):\n",
    "    acc = []\n",
    "    sens = []\n",
    "    esp = []\n",
    "    clf = RF(n_estimators=arboles)\n",
    "\n",
    "    #Complete el código para Árboles de decisión\n",
    "    for i in range(100):\n",
    "\n",
    "        Xtrain,Xtest,Ytrain,Ytest = train_test_split(bd,y,test_size=0.3)  \n",
    "\n",
    "        clf.fit(Xtrain,Ytrain)\n",
    "        Yest = clf.predict(Xtest)\n",
    "        s, e = error_measures(Yest,Ytest)\n",
    "        sens.append(s); esp.append(e)\n",
    "        acc.append(clf.score(Xtest,Ytest))\n",
    "\n",
    "\n",
    "    #print(\"Resultados con Random Forest\\n\")\n",
    "    #print(\"Accuracy: \", np.mean(acc), \"+/-\", np.std(acc))\n",
    "    #print(\"Sensitivity: \", np.mean(sens), \"+/-\", np.std(sens))\n",
    "    #print(\"Especificity: \", np.mean(esp), \"+/-\", np.std(esp))\n",
    "    return 1-np.mean(acc),np.mean(sens),np.mean(esp)\n",
    "\n",
    "a,b,c = RandomForest(Caracteristicas,20)\n",
    "print(\"Accuracy: \", a)\n",
    "print(\"Sensitivity: \", b)\n",
    "print(\"Especificity: \", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorización "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "db = open('Docs.txt', 'r')\n",
    "db_data = []\n",
    "for i in db:\n",
    "    db_data.append(i)\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de Matriz de términos en documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TerminoDoc(db_data):\n",
    "    vector = CountVectorizer(ngram_range=(1,3))    \n",
    "\n",
    "    vector.fit(db_data)\n",
    "\n",
    "    bow = vector.transform(db_data)\n",
    "    return bow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso del esquema TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF(db_data):    \n",
    "    vector = TfidfVectorizer()   \n",
    "\n",
    "    vector.fit(db_data)\n",
    "\n",
    "    bow = vector.transform(db_data)\n",
    "    return bow\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de tablas para mostrar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tablaRegresionLogistica(datos):\n",
    "    errV,sesV,espV = [],[],[]\n",
    "    err,ses,esp = RegresionLogistica(datos)\n",
    "    errV.append(err)\n",
    "    sesV.append(ses)\n",
    "    espV.append(esp)\n",
    "    medidasDict = {\n",
    "        'Error': errV, \n",
    "        'Sensibilidad': sesV,\n",
    "        'Especificidad': espV\n",
    "        }\n",
    "    tabla = pd.DataFrame(data=medidasDict)\n",
    "    \n",
    "    print(tabla)\n",
    "    \n",
    "def tablaKNN(datos):\n",
    "    numeroVecinos = [1,3,5,7,9,15,25]\n",
    "    errores, sensibilidades, especificidades = [],[],[]\n",
    "    for i in numeroVecinos:\n",
    "        err,ses,esp = RandomForest(datos,i)\n",
    "        errores.append(err)\n",
    "        sensibilidades.append(ses)\n",
    "        especificidades.append(esp)\n",
    "\n",
    "    medidasDict = {\n",
    "        '# Vecinos': numeroVecinos, \n",
    "        'Error': errores, \n",
    "        'Sensibilidad': sensibilidades,\n",
    "        'Especificidad': especificidades\n",
    "        }\n",
    "    tabla = pd.DataFrame(data=medidasDict)\n",
    "    \n",
    "    print(tabla)\n",
    "\n",
    "def tablaRandomForest(datos):\n",
    "    numeroVecinos = [10,20,30,40,50]\n",
    "    errores, sensibilidades, especificidades = [],[],[]\n",
    "    for i in numeroVecinos:\n",
    "        err,ses,esp = KNearestNeighbors(datos,i)\n",
    "        errores.append(err)\n",
    "        sensibilidades.append(ses)\n",
    "        especificidades.append(esp)\n",
    "\n",
    "    medidasDict = {\n",
    "        '# Arboles': numeroVecinos, \n",
    "        'Error': errores, \n",
    "        'Sensibilidad': sensibilidades,\n",
    "        'Especificidad': especificidades\n",
    "        }\n",
    "    tabla = pd.DataFrame(data=medidasDict)\n",
    "    \n",
    "    print(tabla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ╒═══════════════════ Regresión logistica ═══════════════════╕ \n",
      "\n",
      "Caracterización  \n",
      "\n",
      "      Error  Sensibilidad  Especificidad\n",
      "0  0.167333      0.833945       0.831258\n",
      "\n",
      "\n",
      "Matriz de terminos en documentos \n",
      "\n",
      "      Error  Sensibilidad  Especificidad\n",
      "0  0.110667      0.932682       0.851553\n",
      "\n",
      "\n",
      "TF-IDF \n",
      "\n",
      "   Error  Sensibilidad  Especificidad\n",
      "0  0.099      0.901129       0.921599\n",
      "╘═════════════════════════════════════════════╛ \n",
      "\n",
      "\n",
      " ╒═══════════════════ KNN ═══════════════════╕ \n",
      "\n",
      "Caracterización  \n",
      "\n",
      "   # Vecinos     Error  Sensibilidad  Especificidad\n",
      "0          1  0.186000      0.785365       0.844476\n",
      "1          3  0.169333      0.795021       0.868185\n",
      "2          5  0.168000      0.791613       0.874569\n",
      "3          7  0.159667      0.810521       0.874929\n",
      "4          9  0.164333      0.788905       0.883137\n",
      "5         15  0.150667      0.825429       0.874085\n",
      "6         25  0.156667      0.801290       0.889930\n",
      "\n",
      "\n",
      "Matriz de terminos en documentos \n",
      "\n",
      "   # Vecinos     Error  Sensibilidad  Especificidad\n",
      "0          1  0.354667      0.708554       0.598620\n",
      "1          3  0.307667      0.817315       0.590883\n",
      "2          5  0.295333      0.867963       0.576704\n",
      "3          7  0.285667      0.879176       0.573292\n",
      "4          9  0.285000      0.896789       0.565259\n",
      "5         15  0.231333      0.935388       0.633264\n",
      "6         25  0.222333      0.947209       0.623114\n",
      "\n",
      "\n",
      "TF-IDF \n",
      "\n",
      "   # Vecinos     Error  Sensibilidad  Especificidad\n",
      "0          1  0.304667      0.726446       0.665051\n",
      "1          3  0.251333      0.785393       0.722093\n",
      "2          5  0.236333      0.827412       0.712023\n",
      "3          7  0.212333      0.873957       0.724877\n",
      "4          9  0.202333      0.888422       0.724276\n",
      "5         15  0.172667      0.906775       0.759566\n",
      "6         25  0.172333      0.921019       0.753758\n",
      "╘═════════════════════════════════════════════╛ \n",
      "\n",
      "\n",
      " ╒═══════════════════ Random Forest ═══════════════════╕ \n",
      "\n",
      "Caracterización  \n",
      "\n",
      "   # Arboles     Error  Sensibilidad  Especificidad\n",
      "0         10  0.161000      0.833197       0.843522\n",
      "1         20  0.163000      0.869259       0.808334\n",
      "2         30  0.173333      0.833393       0.823699\n",
      "3         40  0.185667      0.789804       0.850784\n",
      "4         50  0.243000      0.630131       0.908765\n",
      "\n",
      "\n",
      "Matriz de terminos en documentos \n",
      "\n",
      "   # Arboles     Error  Sensibilidad  Especificidad\n",
      "0         10  0.416333      0.997092       0.170551\n",
      "1         20  0.471000      0.993228       0.070014\n",
      "2         30  0.493000      0.999375       0.027829\n",
      "3         40  0.495000      1.000000       0.003830\n",
      "4         50  0.503000      1.000000       0.003706\n",
      "\n",
      "\n",
      "TF-IDF \n",
      "\n",
      "   # Arboles     Error  Sensibilidad  Especificidad\n",
      "0         10  0.137000      0.765501       0.969865\n",
      "1         20  0.168000      0.703753       0.976154\n",
      "2         30  0.188667      0.666053       0.972002\n",
      "3         40  0.226000      0.621351       0.951263\n",
      "4         50  0.292667      0.517552       0.947732\n",
      "╘═════════════════════════════════════════════╛ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n','╒═══════════════════ Regresión logistica ═══════════════════╕','\\n')\n",
    "print('Caracterización',' \\n')\n",
    "tablaRegresionLogistica(Caracteristicas)\n",
    "print('\\n')\n",
    "print('Matriz de terminos en documentos','\\n')\n",
    "tablaRegresionLogistica(TerminoDoc(db_data))\n",
    "print('\\n')\n",
    "print('TF-IDF','\\n')\n",
    "tablaRegresionLogistica(TFIDF(db_data))\n",
    "print('╘══════════════════════════════════════════════════════╛', '\\n')\n",
    "\n",
    "print('\\n','╒═══════════════════ KNN ═══════════════════╕','\\n')\n",
    "print('Caracterización',' \\n')\n",
    "tablaKNN(Caracteristicas)\n",
    "print('\\n')\n",
    "print('Matriz de terminos en documentos','\\n')\n",
    "tablaKNN(TerminoDoc(db_data))\n",
    "print('\\n')\n",
    "print('TF-IDF','\\n')\n",
    "tablaKNN(TFIDF(db_data))\n",
    "print('╘══════════════════════════════════════════════════════╛', '\\n')\n",
    "\n",
    "print('\\n','╒═══════════════════ Random Forest ═══════════════════╕','\\n')\n",
    "print('Caracterización',' \\n')\n",
    "tablaRandomForest(Caracteristicas)\n",
    "print('\\n')\n",
    "print('Matriz de terminos en documentos','\\n')\n",
    "tablaRandomForest(TerminoDoc(db_data))\n",
    "print('\\n')\n",
    "print('TF-IDF','\\n')\n",
    "tablaRandomForest(TFIDF(db_data))\n",
    "print('╘══════════════════════════════════════════════════════╛', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis\n",
    " 1. Con la base de datos construida a partir de TF-IDF, los resultados obtenidos indican que hay un mejor desempeño clasificando los comentarios en las dos clases propuestas, al calculado usando la caracterizacion de textos usando el recurso lexico MLSenticon, en especial usando el modelo K-nearest neighbors.\n",
    "\n",
    " 2. Usando CountVectorizer la representacion de los documentos como una matriz de terminos en documentos permite una buena clasificacion usando regresion logistica, pero tiene un desempeño malo usando KNN y Random forest, en especial clasificando los documentos negativos, ya que cuenta con una muy baja especificidad usando dichos modelos, esto puede deberse a que la representacion de los documentos como matriz de terminos en documentos, no es apta para la clasificacion usando estos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
